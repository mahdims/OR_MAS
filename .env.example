# LLM Provider Configuration
# Choose one of: openai, gemini, deepseek, qwen, local
PROVIDER=openai

# Model name (depends on provider)
# OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo
# Gemini: gemini-1.5-pro, gemini-1.5-flash
# DeepSeek: deepseek-chat, deepseek-coder
MODEL_NAME=gpt-4o-mini

# API Key (required for cloud providers)
API_KEY=your-api-key-here

# Base URL (required for OpenAI-compatible providers like DeepSeek, Qwen, or local)
# BASE_URL=https://api.deepseek.com/v1
# BASE_URL=http://localhost:8000/v1
